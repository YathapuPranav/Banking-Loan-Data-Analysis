{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YathapuPranav/Banking-Loan-Data-Analysis/blob/main/News_Articles_Collection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ea25fe-3c81-48e8-aee1-dd054a4373ea",
      "metadata": {
        "id": "c1ea25fe-3c81-48e8-aee1-dd054a4373ea",
        "outputId": "e48ecdc2-4151-476b-989b-e7eac45dbc68"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     current_date \u001b[38;5;241m=\u001b[39m next_date\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Optional: Delay to avoid rate limiting (adjust as needed)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     43\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_companies,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_titles,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_links,\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_dates\n\u001b[0;32m     48\u001b[0m })\n\u001b[0;32m     50\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompanies_news_past_1_year.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "import time\n",
        "\n",
        "companies = [\"Google\", \"Amazon\", \"Meta\", \"Microsoft\", \"NVIDIA\", \"Tesla\"]\n",
        "\n",
        "# Set the date range for 1 year\n",
        "end_date = datetime.today()\n",
        "start_date = end_date - timedelta(days=365)\n",
        "\n",
        "all_titles = []\n",
        "all_links = []\n",
        "all_dates = []\n",
        "all_companies = []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    next_date = current_date + timedelta(days=1)\n",
        "\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = next_date.strftime('%Y-%m-%d')\n",
        "\n",
        "    for company in companies:\n",
        "        query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "        encoded_query = urllib.parse.quote(query)\n",
        "\n",
        "        rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "        feed = feedparser.parse(rss_url)\n",
        "\n",
        "        for entry in feed.entries:\n",
        "            all_titles.append(entry.title)\n",
        "            all_links.append(entry.link)\n",
        "            all_dates.append(entry.published)\n",
        "            all_companies.append(company)\n",
        "\n",
        "    current_date = next_date\n",
        "\n",
        "    # Optional: Delay to avoid rate limiting (adjust as needed)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"company\": all_companies,\n",
        "    \"title\": all_titles,\n",
        "    \"link\": all_links,\n",
        "    \"date\": all_dates\n",
        "})\n",
        "\n",
        "df.to_excel(\"companies_news_past_1_year.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "164d8206-cccc-4c75-865a-8c16ec421d30",
      "metadata": {
        "id": "164d8206-cccc-4c75-865a-8c16ec421d30",
        "outputId": "3bad2694-6a73-4409-f29f-f35c05631311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  New Pixel features for better sleep and person...   \n",
            "1  Google Mobility Trends: How has the pandemic c...   \n",
            "2  Google Meet is free. Hereâ€™s how to master its ...   \n",
            "3  Google takes down smartphone service targeting...   \n",
            "4  Google offers employees return to work on 'rot...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMia0FVX...   \n",
            "1  https://news.google.com/rss/articles/CBMiXEFVX...   \n",
            "2  https://news.google.com/rss/articles/CBMiYEFVX...   \n",
            "3  https://news.google.com/rss/articles/CBMicEFVX...   \n",
            "4  https://news.google.com/rss/articles/CBMifEFVX...   \n",
            "\n",
            "                            date  \n",
            "0  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "1  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "2  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "3  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "4  Tue, 02 Jun 2020 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Google\"\n",
        "start_date = datetime(2020, 6, 1)\n",
        "end_date = datetime(2022, 6, 30)\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2020_June2022.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb5dcef-21d8-479f-881f-687b7c085f87",
      "metadata": {
        "id": "4fb5dcef-21d8-479f-881f-687b7c085f87",
        "outputId": "09444745-09ce-4607-b9f7-e7d83a3485ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  A milestone for King's Cross: a local innovati...   \n",
            "1  Google will delete location history data for a...   \n",
            "2  A guide to the Google (Alphabet) stock split 2...   \n",
            "3  Easy Collaboration: 35 Must-Know Tips for Goog...   \n",
            "4  H&M turns to machine learning and artificial i...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMimAFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMimgFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMif0FVX...   \n",
            "3  https://news.google.com/rss/articles/CBMiekFVX...   \n",
            "4  https://news.google.com/rss/articles/CBMirwFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "1  Sat, 02 Jul 2022 07:00:00 GMT  \n",
            "2  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "3  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "4  Fri, 01 Jul 2022 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Google\"\n",
        "start_date = datetime(2022, 7, 1)\n",
        "end_date = datetime(2025, 6,6 )\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2022_June2025.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa158636-1eb5-4887-a7b0-33a234d8339f",
      "metadata": {
        "id": "aa158636-1eb5-4887-a7b0-33a234d8339f",
        "outputId": "6051b8b3-e35d-451a-9f71-0323a0e72b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Dimension named Microsoft Mixed Reality Partne...   \n",
            "1      \"The best IT in the energy industry\" - Uniper   \n",
            "2  Surface Pro 6 Review: The Best 2-in-1 Just Got...   \n",
            "3  Microsoft Stock Could Break Out to New Highs -...   \n",
            "4  Microsoft Takes On Zoom and Slack in a Battle ...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMi3AFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMic0FVX...   \n",
            "2  https://news.google.com/rss/articles/CBMicEFVX...   \n",
            "3  https://news.google.com/rss/articles/CBMiiAFBV...   \n",
            "4  https://news.google.com/rss/articles/CBMiugFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "1  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "2  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "3  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "4  Tue, 02 Jun 2020 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Microsoft\"\n",
        "start_date = datetime(2020, 6, 1)\n",
        "end_date = datetime(2022, 6, 30)\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2020_June2022.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dcbe0e4-90aa-447d-8ad4-35c4c58ebde2",
      "metadata": {
        "id": "0dcbe0e4-90aa-447d-8ad4-35c4c58ebde2",
        "outputId": "51262936-8a0b-419c-ecd7-badc60867e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0       Microsoft Surface Laptop Go 2 Review - PCMag   \n",
            "1  Microsoft Defender For Mac: Is This Some Kind ...   \n",
            "2  Microsoft Azure data centers operating \"with l...   \n",
            "3  Magicrete gains a competitive edge by optimizi...   \n",
            "4  Microsoft is readying a smaller, faster 'Outlo...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMia0FVX...   \n",
            "1  https://news.google.com/rss/articles/CBMiqgFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMi4AFBV...   \n",
            "3  https://news.google.com/rss/articles/CBMiqwFBV...   \n",
            "4  https://news.google.com/rss/articles/CBMitwFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Sat, 02 Jul 2022 07:00:00 GMT  \n",
            "1  Sat, 02 Jul 2022 07:00:00 GMT  \n",
            "2  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "3  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "4  Fri, 01 Jul 2022 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Microsoft\"\n",
        "start_date = datetime(2022, 7, 1)\n",
        "end_date = datetime(2025, 6,6 )\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2022_June2025.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a20a79-d4c6-499a-aecc-a4b6c4d77bd0",
      "metadata": {
        "id": "85a20a79-d4c6-499a-aecc-a4b6c4d77bd0",
        "outputId": "cb76c32c-c6b2-4ca8-c8d8-b37bd997edd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Facebook parent Meta officially kills Zeewolde...   \n",
            "1  Meta Slashes Hiring As It Braces For Downturn ...   \n",
            "2  A review and meta-analysis of mitigation measu...   \n",
            "3  Metaâ€™s shutting down its digital wallet, Novi ...   \n",
            "4  Meta Was Restricting Abortion Content All Alon...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMi0gFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMipgFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMidkFVX...   \n",
            "3  https://news.google.com/rss/articles/CBMiowFBV...   \n",
            "4  https://news.google.com/rss/articles/CBMib0FVX...   \n",
            "\n",
            "                            date  \n",
            "0  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "1  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "2  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "3  Sat, 02 Jul 2022 07:00:00 GMT  \n",
            "4  Fri, 01 Jul 2022 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Meta\"\n",
        "start_date = datetime(2022, 7, 1)\n",
        "end_date = datetime(2025, 6,6 )\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2022_June2025.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8129ffd3-b81a-4cf6-8d36-e6573016abd9",
      "metadata": {
        "id": "8129ffd3-b81a-4cf6-8d36-e6573016abd9"
      },
      "outputs": [],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Meta\"\n",
        "start_date = datetime(2020, 6, 1)\n",
        "end_date = datetime(2022, 6, 30)\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2020_June2022.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a108ad-44d5-4134-9740-30c369176615",
      "metadata": {
        "id": "e6a108ad-44d5-4134-9740-30c369176615",
        "outputId": "fbe57ba4-6593-4779-fa68-0699898a04df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Amazon Faces A Crucible Moment With Employees ...   \n",
            "1  Amazon does not infringe Davidoff trade mark b...   \n",
            "2  Public health issues from crude-oil production...   \n",
            "3  Verkkokauppa.com â€“ is it Finlandâ€™s Amazon? - T...   \n",
            "4  As the pandemic continues to accelerate, so do...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMinwFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMitAFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMidkFVX...   \n",
            "3  https://news.google.com/rss/articles/CBMifkFVX...   \n",
            "4  https://news.google.com/rss/articles/CBMivAFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "1  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "2  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "3  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "4  Mon, 01 Jun 2020 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Amazon\"\n",
        "start_date = datetime(2020, 6, 1)\n",
        "end_date = datetime(2022, 6, 30)\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2020_June2022.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6084eff7-a7b2-4f47-801a-637a3d29ed30",
      "metadata": {
        "id": "6084eff7-a7b2-4f47-801a-637a3d29ed30",
        "outputId": "dd5df52a-8282-40d5-c807-017671ee3244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Amazon signs Champions League football streami...   \n",
            "1  My people have lived in the Amazon for 6,000 y...   \n",
            "2  BT Sport and Amazon to share 2024-27 Champions...   \n",
            "3  Amazon wild west: where drugs, fish and loggin...   \n",
            "4  Amazon fires at 15 year high in June as UK con...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMicEFVX...   \n",
            "1  https://news.google.com/rss/articles/CBMixAFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMiswFBV...   \n",
            "3  https://news.google.com/rss/articles/CBMisAFBV...   \n",
            "4  https://news.google.com/rss/articles/CBMi0wFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "1  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "2  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "3  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "4  Fri, 01 Jul 2022 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Amazon\"\n",
        "start_date = datetime(2022, 7, 1)\n",
        "end_date = datetime(2025, 6,6 )\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2022_June2025.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7758d08e-4918-443f-8860-848a56ba0eeb",
      "metadata": {
        "id": "7758d08e-4918-443f-8860-848a56ba0eeb",
        "outputId": "d1e5f828-74f3-4b6e-e617-29383cbc2841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  GeForce Now Switches To Opt-In System After Se...   \n",
            "1  News: Basler Introduces Embedded Vision Soluti...   \n",
            "2  AMD Ryzen 7 3700X 8 Core CPU & NVIDIA GeForce ...   \n",
            "3  HP unveils its first 16-inch gaming laptop, th...   \n",
            "4  Lenovo Legion Tower 5i Review: The Gamerâ€™s Bes...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMinwFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMisAFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMiswFBV...   \n",
            "3  https://news.google.com/rss/articles/CBMilwFBV...   \n",
            "4  https://news.google.com/rss/articles/CBMigAFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "1  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "2  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "3  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "4  Tue, 02 Jun 2020 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"NVIDIA\"\n",
        "start_date = datetime(2020, 6, 1)\n",
        "end_date = datetime(2022, 6, 30)\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2020_June2022.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a27f050-1d36-49a4-8f5a-5190c55f7898",
      "metadata": {
        "id": "2a27f050-1d36-49a4-8f5a-5190c55f7898",
        "outputId": "5aca31e5-80f2-4a3f-b5f8-72827c3ecfb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Nvidia Adds Automatic Game Mode, Night Listeni...   \n",
            "1  If this new Nvidia RTX 4090 rumor is true, AMD...   \n",
            "2  HP and NVIDIA release â€˜uniqueâ€™ fintech sitcom ...   \n",
            "3  Nvidia Shield â€˜night listeningâ€™ feature balanc...   \n",
            "4  Alleged NVIDIA GeForce RTX 4090 Ti FE Cooler D...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMimgFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMipAFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMijwFBV...   \n",
            "3  https://news.google.com/rss/articles/CBMic0FVX...   \n",
            "4  https://news.google.com/rss/articles/CBMirgFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "1  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "2  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "3  Sat, 02 Jul 2022 07:00:00 GMT  \n",
            "4  Fri, 01 Jul 2022 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"NVIDIA\"\n",
        "start_date = datetime(2022, 7, 1)\n",
        "end_date = datetime(2025, 6,6 )\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2022_June2025.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea71ee3-18a6-4859-8552-a9b715e34c46",
      "metadata": {
        "id": "cea71ee3-18a6-4859-8552-a9b715e34c46",
        "outputId": "7650d3a2-1f5d-486f-a3dd-3c6a1e85f060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Tesla In Taiwan Crashes Directly Into Overturn...   \n",
            "1  Tesla Model 3 'on Autopilot mode' crashes into...   \n",
            "2  Tesla Joins Long Line of Advertisers That Went...   \n",
            "3  Tesla launches â€˜Model 3 All Weather Protection...   \n",
            "4  â€˜Tesla Cloneâ€™ Xpeng Has A Website Just Like Te...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMi3wFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMizwFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMinwFBV...   \n",
            "3  https://news.google.com/rss/articles/CBMijgFBV...   \n",
            "4  https://news.google.com/rss/articles/CBMiiwFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Tue, 02 Jun 2020 07:00:00 GMT  \n",
            "1  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "2  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "3  Mon, 01 Jun 2020 07:00:00 GMT  \n",
            "4  Tue, 02 Jun 2020 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Tesla\"\n",
        "start_date = datetime(2020, 6, 1)\n",
        "end_date = datetime(2022, 6, 30)\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2020_June2022.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690946e7-52d6-4a2d-83ec-9f5b4fe597b9",
      "metadata": {
        "id": "690946e7-52d6-4a2d-83ec-9f5b4fe597b9",
        "outputId": "585710a2-7235-44c0-c3c0-a189ba42aafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Tesla hit by new lawsuit alleging racial abuse...   \n",
            "1  Tesla hit by new lawsuit alleging racial abuse...   \n",
            "2  Tesla Sales Slow as the Pandemic Hobbles Produ...   \n",
            "3  Teslaâ€™s run of record quarterly deliveries com...   \n",
            "4  You'll soon be able to connect your Wall Conne...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://news.google.com/rss/articles/CBMingFBV...   \n",
            "1  https://news.google.com/rss/articles/CBMizwFBV...   \n",
            "2  https://news.google.com/rss/articles/CBMicEFVX...   \n",
            "3  https://news.google.com/rss/articles/CBMipAFBV...   \n",
            "4  https://news.google.com/rss/articles/CBMi0gFBV...   \n",
            "\n",
            "                            date  \n",
            "0  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "1  Fri, 01 Jul 2022 07:00:00 GMT  \n",
            "2  Sat, 02 Jul 2022 07:00:00 GMT  \n",
            "3  Sat, 02 Jul 2022 07:00:00 GMT  \n",
            "4  Sat, 02 Jul 2022 07:00:00 GMT  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import urllib.parse\n",
        "\n",
        "company = \"Tesla\"\n",
        "start_date = datetime(2022, 7, 1)\n",
        "end_date = datetime(2025, 6,6 )\n",
        "\n",
        "titles, links, dates = [], [], []\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    day_start = current_date.strftime('%Y-%m-%d')\n",
        "    day_end = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "    query = f\"{company} after:{day_start} before:{day_end}\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-GB&gl=GB&ceid=GB:en\"\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        titles.append(entry.title)\n",
        "        links.append(entry.link)\n",
        "        dates.append(entry.published)\n",
        "\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"title\": titles,\n",
        "    \"link\": links,\n",
        "    \"date\": dates\n",
        "})\n",
        "\n",
        "df.to_excel(f\"{company}_news_June2022_June2025.xlsx\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5ffbc4-f0bf-452c-9457-11392a731b04",
      "metadata": {
        "id": "ec5ffbc4-f0bf-452c-9457-11392a731b04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be64bebe-dd55-48dc-ae83-373819afb639",
      "metadata": {
        "id": "be64bebe-dd55-48dc-ae83-373819afb639"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}